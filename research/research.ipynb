{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3801a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ada80f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.read_csv('../data/products.csv')\n",
    "users_df = pd.read_csv('../data/users.csv')\n",
    "orders_df = pd.read_csv('../data/orders.csv')\n",
    "order_items_df = pd.read_csv('../data/order_items.csv')\n",
    "inventory_items_df = pd.read_csv('../data/inventory_items.csv')\n",
    "distribution_centers_df = pd.read_csv('../data/distribution_centers.csv')\n",
    "events_df = pd.read_csv('../data/events.csv')\n",
    "\n",
    "dataframes = {\n",
    "    \"products\": products_df,\n",
    "    \"users\": users_df,\n",
    "    \"orders\": orders_df,\n",
    "    \"order_items\": order_items_df,\n",
    "    \"inventory_items\": inventory_items_df,\n",
    "    \"distribution_centers\": distribution_centers_df,\n",
    "    \"events\": events_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a5ee968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRODUCTS DataFrame:\n",
      "      id     cost     category  \\\n",
      "0  13842  2.51875  Accessories   \n",
      "1  13928  2.33835  Accessories   \n",
      "2  14115  4.87956  Accessories   \n",
      "3  14157  4.64877  Accessories   \n",
      "4  14273  6.50793  Accessories   \n",
      "\n",
      "                                                name brand  retail_price  \\\n",
      "0   Low Profile Dyed Cotton Twill Cap - Navy W39S55D    MG          6.25   \n",
      "1  Low Profile Dyed Cotton Twill Cap - Putty W39S55D    MG          5.95   \n",
      "2       Enzyme Regular Solid Army Caps-Black W35S45D    MG         10.99   \n",
      "3  Enzyme Regular Solid Army Caps-Olive W35S45D (...    MG         10.99   \n",
      "4              Washed Canvas Ivy Cap - Black W11S64C    MG         15.99   \n",
      "\n",
      "  department                               sku  distribution_center_id  \n",
      "0      Women  EBD58B8A3F1D72F4206201DA62FB1204                       1  \n",
      "1      Women  2EAC42424D12436BDD6A5B8A88480CC3                       1  \n",
      "2      Women  EE364229B2791D1EF9355708EFF0BA34                       1  \n",
      "3      Women  00BD13095D06C20B11A2993CA419D16B                       1  \n",
      "4      Women  F531DC20FDE20B7ADF3A73F52B71D0AF                       1  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "USERS DataFrame:\n",
      "      id   first_name last_name                           email  age gender  \\\n",
      "0    457      Timothy      Bush         timothybush@example.net   65      M   \n",
      "1   6578    Elizabeth  Martinez   elizabethmartinez@example.com   34      F   \n",
      "2  36280  Christopher   Mendoza  christophermendoza@example.net   13      M   \n",
      "3  60193        Jimmy    Conner         jimmyconner@example.com   64      M   \n",
      "4  64231      Natasha    Wilson       natashawilson@example.net   25      F   \n",
      "\n",
      "  state                street_address postal_code        city country  \\\n",
      "0  Acre           87620 Johnson Hills   69917-400  Rio Branco  Brasil   \n",
      "1  Acre             1705 Nielsen Land   69917-400  Rio Branco  Brasil   \n",
      "2  Acre      125 Turner Isle Apt. 264   69917-400  Rio Branco  Brasil   \n",
      "3  Acre     0966 Jose Branch Apt. 008   69917-400  Rio Branco  Brasil   \n",
      "4  Acre  20798 Phillip Trail Apt. 392   69917-400  Rio Branco  Brasil   \n",
      "\n",
      "   latitude  longitude traffic_source                 created_at  \n",
      "0 -9.945568  -67.83561         Search  2022-07-19 13:51:00+00:00  \n",
      "1 -9.945568  -67.83561         Search  2023-11-08 18:49:00+00:00  \n",
      "2 -9.945568  -67.83561          Email  2019-08-24 06:10:00+00:00  \n",
      "3 -9.945568  -67.83561         Search  2020-02-15 11:26:00+00:00  \n",
      "4 -9.945568  -67.83561         Search  2020-03-13 06:45:00+00:00  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ORDERS DataFrame:\n",
      "   order_id  user_id     status gender                 created_at returned_at  \\\n",
      "0         8        5  Cancelled      F  2022-10-20 10:03:00+00:00         NaN   \n",
      "1        60       44  Cancelled      F  2023-01-20 02:12:00+00:00         NaN   \n",
      "2        64       46  Cancelled      F  2021-12-06 09:11:00+00:00         NaN   \n",
      "3        89       65  Cancelled      F  2020-08-13 09:58:00+00:00         NaN   \n",
      "4       102       76  Cancelled      F  2023-01-17 08:17:00+00:00         NaN   \n",
      "\n",
      "  shipped_at delivered_at  num_of_item  \n",
      "0        NaN          NaN            3  \n",
      "1        NaN          NaN            1  \n",
      "2        NaN          NaN            1  \n",
      "3        NaN          NaN            1  \n",
      "4        NaN          NaN            2  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ORDER_ITEMS DataFrame:\n",
      "       id  order_id  user_id  product_id  inventory_item_id     status  \\\n",
      "0  152013    104663    83582       14235             410368  Cancelled   \n",
      "1   40993     28204    22551       14235             110590   Complete   \n",
      "2   51224     35223    28215       14235             138236   Complete   \n",
      "3   36717     25278    20165       14235              99072    Shipped   \n",
      "4  131061     90241    71954       14235             353798    Shipped   \n",
      "\n",
      "                  created_at                 shipped_at  \\\n",
      "0  2023-05-07 06:08:40+00:00                        NaN   \n",
      "1  2023-03-14 03:47:21+00:00  2023-03-15 22:57:00+00:00   \n",
      "2  2023-12-05 13:25:30+00:00  2023-12-06 01:20:00+00:00   \n",
      "3  2023-12-22 20:48:19+00:00  2023-12-24 16:44:00+00:00   \n",
      "4  2022-06-19 16:57:59+00:00  2022-06-19 19:29:00+00:00   \n",
      "\n",
      "                delivered_at returned_at  sale_price  \n",
      "0                        NaN         NaN        0.02  \n",
      "1  2023-03-18 01:08:00+00:00         NaN        0.02  \n",
      "2  2023-12-10 10:04:00+00:00         NaN        0.02  \n",
      "3                        NaN         NaN        0.02  \n",
      "4                        NaN         NaN        0.02  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "INVENTORY_ITEMS DataFrame:\n",
      "      id  product_id                 created_at                    sold_at  \\\n",
      "0  67971       13844  2022-07-02 07:09:20+00:00  2022-07-24 06:33:20+00:00   \n",
      "1  67972       13844  2023-12-20 03:28:00+00:00                        NaN   \n",
      "2  67973       13844  2023-06-04 02:53:00+00:00                        NaN   \n",
      "3  72863       13844  2021-10-16 22:58:52+00:00  2021-11-22 02:19:52+00:00   \n",
      "4  72864       13844  2021-08-07 16:33:00+00:00                        NaN   \n",
      "\n",
      "      cost product_category            product_name       product_brand  \\\n",
      "0  2.76804      Accessories  (ONE) 1 Satin Headband  Funny Girl Designs   \n",
      "1  2.76804      Accessories  (ONE) 1 Satin Headband  Funny Girl Designs   \n",
      "2  2.76804      Accessories  (ONE) 1 Satin Headband  Funny Girl Designs   \n",
      "3  2.76804      Accessories  (ONE) 1 Satin Headband  Funny Girl Designs   \n",
      "4  2.76804      Accessories  (ONE) 1 Satin Headband  Funny Girl Designs   \n",
      "\n",
      "   product_retail_price product_department                       product_sku  \\\n",
      "0                  6.99              Women  2A3E953A5E3D81E67945BCE5519F84C8   \n",
      "1                  6.99              Women  2A3E953A5E3D81E67945BCE5519F84C8   \n",
      "2                  6.99              Women  2A3E953A5E3D81E67945BCE5519F84C8   \n",
      "3                  6.99              Women  2A3E953A5E3D81E67945BCE5519F84C8   \n",
      "4                  6.99              Women  2A3E953A5E3D81E67945BCE5519F84C8   \n",
      "\n",
      "   product_distribution_center_id  \n",
      "0                               7  \n",
      "1                               7  \n",
      "2                               7  \n",
      "3                               7  \n",
      "4                               7  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "DISTRIBUTION_CENTERS DataFrame:\n",
      "   id            name  latitude  longitude\n",
      "0   1      Memphis TN   35.1174   -89.9711\n",
      "1   2      Chicago IL   41.8369   -87.6847\n",
      "2   3      Houston TX   29.7604   -95.3698\n",
      "3   4  Los Angeles CA   34.0500  -118.2500\n",
      "4   5  New Orleans LA   29.9500   -90.0667\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "EVENTS DataFrame:\n",
      "        id  user_id  sequence_number                            session_id  \\\n",
      "0  2198523      NaN                3  83889ed2-2adc-4b9a-af5d-154f6998e778   \n",
      "1  1773216      NaN                3  7a3fc3f2-e84f-44fe-8876-eff76741f7a3   \n",
      "2  2380515      NaN                3  13d9b2fb-eee1-43fd-965c-267b38dd7125   \n",
      "3  2250597      NaN                3  96f1d44e-9621-463c-954c-d8deb7fffe7f   \n",
      "4  1834446      NaN                3  d09dce10-a7cb-47d3-a9af-44975566fa03   \n",
      "\n",
      "                  created_at       ip_address          city      state  \\\n",
      "0  2021-06-17 17:30:00+00:00    138.143.9.202     São Paulo  São Paulo   \n",
      "1  2020-08-07 08:41:00+00:00    85.114.141.79  Santa Isabel  São Paulo   \n",
      "2  2021-02-15 18:48:00+00:00  169.250.255.132     Mairiporã  São Paulo   \n",
      "3  2022-03-30 10:56:00+00:00   137.25.222.160       Cajamar  São Paulo   \n",
      "4  2019-09-05 01:18:00+00:00    161.114.4.174     São Paulo  São Paulo   \n",
      "\n",
      "  postal_code browser traffic_source      uri event_type  \n",
      "0   02675-031  Chrome        Adwords  /cancel     cancel  \n",
      "1   07500-000  Safari        Adwords  /cancel     cancel  \n",
      "2   07600-000      IE        Adwords  /cancel     cancel  \n",
      "3   07750-000  Chrome        Adwords  /cancel     cancel  \n",
      "4   09581-680  Chrome          Email  /cancel     cancel  \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, df in dataframes.items():\n",
    "    print(f\"\\n{name.upper()} DataFrame:\")\n",
    "    print(df.head())\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22525aa8",
   "metadata": {},
   "source": [
    "### SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cf4243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'products' created in database 'ecommerce.db'.\n",
      "Table 'users' created in database 'ecommerce.db'.\n",
      "Table 'orders' created in database 'ecommerce.db'.\n",
      "Table 'order_items' created in database 'ecommerce.db'.\n",
      "Table 'inventory_items' created in database 'ecommerce.db'.\n",
      "Table 'distribution_centers' created in database 'ecommerce.db'.\n",
      "Table 'events' created in database 'ecommerce.db'.\n",
      "All tables have been created and data has been inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "db_dir_path = 'db_data'\n",
    "db = \"ecommerce.db\"\n",
    "\n",
    "if not os.path.exists(db_dir_path):\n",
    "    os.makedirs(db_dir_path)\n",
    "\n",
    "conn = sqlite3.connect(os.path.join(db_dir_path, db))\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    df.to_sql(name, conn, if_exists='replace', index=False)\n",
    "    print(f\"Table '{name}' created in database '{db}'.\")\n",
    "\n",
    "conn.close()\n",
    "print(\"All tables have been created and data has been inserted successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ba07a",
   "metadata": {},
   "source": [
    "### Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eadbf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda950d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547b81dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich liebe Programmieren.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to German. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6582299",
   "metadata": {},
   "source": [
    "### Schema Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fcd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(os.path.join(db_dir_path, db))\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"DATABASE SCHEMA\\n\" + \"=\" * 80)\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    print(f\"\\nTable: {table_name.upper()}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Fetch schema for that table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    columns = cursor.fetchall()\n",
    "\n",
    "    # Convert to dataframe with only name + type\n",
    "    schema_df = pd.DataFrame(\n",
    "        columns, columns=[\"cid\", \"name\", \"type\", \"notnull\", \"dflt_value\", \"pk\"]\n",
    "    )\n",
    "    schema_df = schema_df[[\"name\", \"type\"]]\n",
    "    schema_df.columns = [\"Column Name\", \"Data Type\"]\n",
    "\n",
    "    print(schema_df.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cdc9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_DEFINITION = \"\"\"\n",
    "TABLE: PRODUCTS\n",
    "Description: Catalog of items available for sale.\n",
    "COLUMNS:\n",
    "- id (INTEGER): PK. Unique identifier for the product.\n",
    "- cost (REAL): The cost to manufacture or acquire the item (not the sale price).\n",
    "- category (TEXT): High-level product category (e.g., 'Accessories', 'Outerwear').\n",
    "- name (TEXT): The commercial name of the product.\n",
    "- brand (TEXT): The brand manufacturer.\n",
    "- retail_price (REAL): The suggested MSRP or list price of the item.\n",
    "- department (TEXT): Gender or demographic target (e.g., 'Men', 'Women').\n",
    "- sku (TEXT): Stock Keeping Unit code.\n",
    "- distribution_center_id (INTEGER): FK. Links to DISTRIBUTION_CENTERS table (location where stocked).\n",
    "\n",
    "TABLE: USERS\n",
    "Description: Registered customers and their demographic data.\n",
    "COLUMNS:\n",
    "- id (INTEGER): PK. Unique identifier for the user.\n",
    "- first_name (TEXT): User's first name.\n",
    "- last_name (TEXT): User's last name.\n",
    "- email (TEXT): User's email address.\n",
    "- age (INTEGER): User's age.\n",
    "- gender (TEXT): User's gender (M/F).\n",
    "- state (TEXT): State of residence.\n",
    "- street_address (TEXT): Street address.\n",
    "- postal_code (TEXT): Zip/Postal code.\n",
    "- city (TEXT): City of residence.\n",
    "- country (TEXT): Country of residence.\n",
    "- latitude (REAL): GPS latitude of user address.\n",
    "- longitude (REAL): GPS longitude of user address.\n",
    "- traffic_source (TEXT): Marketing channel that acquired the user (e.g., 'Search', 'Organic').\n",
    "- created_at (TIMESTAMP): Date and time the account was created.\n",
    "\n",
    "TABLE: ORDERS\n",
    "Description: Summary of a purchase event (basket level).\n",
    "COLUMNS:\n",
    "- order_id (INTEGER): PK. Unique identifier for the order.\n",
    "- user_id (INTEGER): FK. Links to USERS table.\n",
    "- status (TEXT): Current state of the order (e.g., 'Complete', 'Cancelled', 'Returned').\n",
    "- gender (TEXT): Gender associated with the order items (often redundant with User gender).\n",
    "- created_at (TIMESTAMP): Timestamp when the order was placed.\n",
    "- returned_at (TIMESTAMP): Timestamp if/when the order was returned.\n",
    "- shipped_at (TIMESTAMP): Timestamp when the order left the warehouse.\n",
    "- delivered_at (TIMESTAMP): Timestamp when the order reached the customer.\n",
    "- num_of_item (INTEGER): Total count of items in this order.\n",
    "\n",
    "TABLE: ORDER_ITEMS\n",
    "Description: Individual line items within an order. Use this for revenue calculations.\n",
    "COLUMNS:\n",
    "- id (INTEGER): PK. Unique identifier for the line item.\n",
    "- order_id (INTEGER): FK. Links to ORDERS table.\n",
    "- user_id (INTEGER): FK. Links to USERS table.\n",
    "- product_id (INTEGER): FK. Links to PRODUCTS table.\n",
    "- inventory_item_id (INTEGER): FK. Links to INVENTORY_ITEMS table (specific stock instance).\n",
    "- status (TEXT): Status of this specific item (e.g., 'Returned', 'Complete').\n",
    "- created_at (TIMESTAMP): Purchase timestamp.\n",
    "- shipped_at (TIMESTAMP): Shipping timestamp.\n",
    "- delivered_at (TIMESTAMP): Delivery timestamp.\n",
    "- returned_at (TIMESTAMP): Return timestamp.\n",
    "- sale_price (REAL): The actual price the user paid for this item (Revenue).\n",
    "\n",
    "TABLE: INVENTORY_ITEMS\n",
    "Description: Historical log of every specific physical item in the warehouse.\n",
    "COLUMNS:\n",
    "- id (INTEGER): PK. Unique identifier for the inventory unit.\n",
    "- product_id (INTEGER): FK. Links to PRODUCTS table.\n",
    "- created_at (TIMESTAMP): When the item arrived in inventory.\n",
    "- sold_at (TIMESTAMP): When the item was sold (NULL if currently in stock).\n",
    "- cost (REAL): Cost of this specific inventory batch.\n",
    "- product_category (TEXT): Redundant snapshot of product category.\n",
    "- product_name (TEXT): Redundant snapshot of product name.\n",
    "- product_brand (TEXT): Redundant snapshot of brand.\n",
    "- product_retail_price (REAL): Redundant snapshot of retail price.\n",
    "- product_department (TEXT): Redundant snapshot of department.\n",
    "- product_sku (TEXT): Redundant snapshot of SKU.\n",
    "- product_distribution_center_id (INTEGER): FK. Links to DISTRIBUTION_CENTERS table.\n",
    "\n",
    "TABLE: DISTRIBUTION_CENTERS\n",
    "Description: Physical warehouse locations.\n",
    "COLUMNS:\n",
    "- id (INTEGER): PK. Unique identifier for the distribution center.\n",
    "- name (TEXT): Name of the facility (e.g., 'Memphis TN').\n",
    "- latitude (REAL): GPS latitude of the facility.\n",
    "- longitude (REAL): GPS longitude of the facility.\n",
    "\n",
    "TABLE: EVENTS\n",
    "Description: Web traffic logs (views, clicks, interactions).\n",
    "COLUMNS:\n",
    "- id (INTEGER): PK. Unique identifier for the event log.\n",
    "- user_id (REAL): FK. Links to USERS (can be NULL for guest visitors).\n",
    "- sequence_number (INTEGER): Order of events within a session.\n",
    "- session_id (TEXT): Unique ID for the browsing session.\n",
    "- created_at (TIMESTAMP): Timestamp of the event.\n",
    "- ip_address (TEXT): User's IP address.\n",
    "- city (TEXT): Estimated city based on IP.\n",
    "- state (TEXT): Estimated state based on IP.\n",
    "- postal_code (TEXT): Estimated zip code based on IP.\n",
    "- browser (TEXT): Browser used (e.g., 'Chrome', 'Safari').\n",
    "- traffic_source (TEXT): Marketing source for this session.\n",
    "- uri (TEXT): The specific URL path visited.\n",
    "- event_type (TEXT): Type of interaction (e.g., 'product', 'department', 'cart', 'purchase').\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b69c4d",
   "metadata": {},
   "source": [
    "### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd230af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class GraphState(MessagesState):\n",
    "    is_question_relavant: bool\n",
    "    user_query: str\n",
    "    sql_query_generated: str\n",
    "    result_for_sql_query: str\n",
    "    final_answer: str\n",
    "    error_message: str\n",
    "    curr_iteration: int\n",
    "    needs_plotly_figure: bool\n",
    "    type_of_plotly_figure: str\n",
    "    plotly_figure_json_string: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a430da8",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd4f3a",
   "metadata": {},
   "source": [
    "#### Guardrails Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ef39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GuardrailsResponse(BaseModel):\n",
    "    is_question_relavant: bool = Field(\n",
    "        description=\"Indicates if the user's query is relevant to the e-commerce database.\",\n",
    "    )\n",
    "    is_greeting: bool = Field(\n",
    "        description=\"Indicates if the user's query is a greeting message.\",\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Explanation for the classification decision.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab439217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def guardrails_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"Validates if user query is relevant to the e-commerce database\"\"\"\n",
    "    user_query = state[\"user_query\"]\n",
    "\n",
    "    prompt = f\"\"\"You are a guardrails agent for an e-commerce SQL query system. Analyze if the user's question can be answered using the available database.\n",
    "\n",
    "DATABASE SCOPE:\n",
    "The system has access to an e-commerce database containing:\n",
    "- Products: catalog, pricing, categories, brands, departments\n",
    "- Users: customer demographics, locations, registration info\n",
    "- Orders: transactions, status tracking, delivery timestamps\n",
    "- Order Items: line-level details, revenue data\n",
    "- Inventory Items: stock levels, warehouse tracking\n",
    "- Distribution Centers: warehouse locations\n",
    "- Events: user behavior, web analytics, session tracking\n",
    "\n",
    "CLASSIFICATION RULES:\n",
    "\n",
    "1. GREETING - Casual conversational starters:\n",
    "   - \"Hi\", \"Hello\", \"Hey there\"\n",
    "   - \"Good morning/afternoon/evening\"\n",
    "   - \"How are you doing?\"\n",
    "   \n",
    "2. IN-SCOPE - Questions answerable with database:\n",
    "   - Sales analytics: \"What was total revenue in 2022?\"\n",
    "   - Product queries: \"Which brand has highest sales?\"\n",
    "   - Customer analysis: \"How many users from Texas?\"\n",
    "   - Inventory questions: \"Show products out of stock\"\n",
    "   - Trend analysis: \"Monthly order trends\"\n",
    "   - Behavioral insights: \"What pages do users visit most?\"\n",
    "   \n",
    "3. OUT-OF-SCOPE - Cannot be answered with this database:\n",
    "   - Personal information: \"What's my order history?\" (no authentication context)\n",
    "   - Future predictions: \"What will sell next month?\" (no ML capability)\n",
    "   - External data: \"Compare our prices to competitors\"\n",
    "   - General knowledge: \"How does e-commerce work?\"\n",
    "   - Unrelated topics: \"Tell me a joke\", \"Weather forecast\"\n",
    "   - Real-time data: \"Current inventory right now\" (data is historical)\n",
    "\n",
    "User Question: \"{user_query}\"\n",
    "\n",
    "Guidelines:\n",
    "- If greeting: set is_greeting=true, is_question_relavant=false\n",
    "- If ambiguous but potentially answerable: mark is_question_relavant=true\n",
    "- Be permissive - favor is_question_relavant=true when uncertain\"\"\"\n",
    "\n",
    "    structured_llm = llm.with_structured_output(GuardrailsResponse)\n",
    "\n",
    "    response = structured_llm.invoke(prompt)\n",
    "\n",
    "    state[\"is_question_relavant\"] = response.is_question_relavant\n",
    "    is_greeting = response.is_greeting\n",
    "\n",
    "    if is_greeting:\n",
    "        state[\"final_answer\"] = (\n",
    "            \"Hello! How can I assist you with e-commerce data today?\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    if not state[\"is_question_relavant\"]:\n",
    "        state[\"final_answer\"] = (\n",
    "            \"I'm sorry, but your question is outside the scope of the e-commerce database I have access to. \"\n",
    "            \"Please ask something related to products, users, orders, inventory, or sales analytics.\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0fe08",
   "metadata": {},
   "source": [
    "#### SQL Generation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2adf8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLGenerationResponse(BaseModel):\n",
    "    sql_query: str = Field(\n",
    "        description=\"The generated SQL query based on the user's question.\",\n",
    "    )\n",
    "    explanation: str = Field(\n",
    "        description=\"Brief explanation of what the query does (max 30 words).\",\n",
    "    )\n",
    "\n",
    "\n",
    "def sql_generation_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"Generate SQL query from natural language question\"\"\"\n",
    "    user_query = state[\"user_query\"]\n",
    "    iteration = state.get(\"curr_iteration\", 0)\n",
    "\n",
    "    prompt = f\"\"\"You are an expert SQL developer specializing in SQLite databases. Convert the user's natural language question into a valid, optimized SQLite query.\n",
    "\n",
    "{SCHEMA_DEFINITION}\n",
    "\n",
    "QUERY GENERATION RULES:\n",
    "\n",
    "1. SCHEMA COMPLIANCE:\n",
    "   - Use ONLY tables and columns defined in the schema above\n",
    "   - Respect data types (TEXT, INTEGER, REAL, TIMESTAMP)\n",
    "   - Follow foreign key relationships for JOINs\n",
    "\n",
    "2. SQL BEST PRACTICES:\n",
    "   - Use explicit JOIN syntax (INNER JOIN, LEFT JOIN) with ON clauses\n",
    "   - Apply WHERE filters before aggregations\n",
    "   - Use meaningful table aliases (p for products, u for users, o for orders)\n",
    "   - Add ORDER BY for ranked results\n",
    "   - Include LIMIT 10 unless user specifies a different number\n",
    "\n",
    "3. AGGREGATIONS & ANALYTICS:\n",
    "   - Use COUNT, SUM, AVG, MIN, MAX appropriately\n",
    "   - GROUP BY required columns when using aggregates\n",
    "   - Use HAVING for post-aggregation filters\n",
    "   - Calculate revenue using order_items.sale_price (NOT products.retail_price)\n",
    "\n",
    "4. DATE HANDLING:\n",
    "   - Dates are stored as TEXT in ISO format (YYYY-MM-DD HH:MM:SS)\n",
    "   - Use DATE() function for date comparisons\n",
    "   - Use strftime() for date formatting and extraction\n",
    "\n",
    "5. REVENUE CALCULATIONS:\n",
    "   - Always use order_items.sale_price for actual revenue\n",
    "   - Join with orders table to filter by status (exclude 'Cancelled', 'Returned')\n",
    "   - Consider order status when calculating metrics\n",
    "\n",
    "6. COMMON PATTERNS:\n",
    "   - Top N queries: ORDER BY ... DESC LIMIT N\n",
    "   - Trend analysis: GROUP BY strftime('%Y-%m', created_at)\n",
    "   - Customer segmentation: JOIN users with orders/order_items\n",
    "   - Product analytics: JOIN products with order_items\n",
    "\n",
    "User Question: \"{user_query}\"\n",
    "\n",
    "Generate a single, executable SQL query. No markdown formatting, no explanations in the query itself.\n",
    "\n",
    "SQL Query:\"\"\"\n",
    "\n",
    "    structured_llm = llm.with_structured_output(SQLGenerationResponse)\n",
    "\n",
    "    response = structured_llm.invoke(prompt)\n",
    "\n",
    "    # Clean the SQL query\n",
    "    sql_query = response.sql_query.strip()\n",
    "    sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "    state[\"sql_query_generated\"] = sql_query\n",
    "    state[\"curr_iteration\"] = iteration + 1\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a23587",
   "metadata": {},
   "source": [
    "#### SQL Execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a6962ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Executes the generated SQL query and handles multiple queries if present.\n",
    "\n",
    "    This function:\n",
    "    1. Splits the SQL query into individual statements (separated by semicolons)\n",
    "    2. Executes each statement sequentially\n",
    "    3. Formats results as DataFrames for readability\n",
    "    4. Handles errors gracefully\n",
    "    5. Stores results in state for downstream processing\n",
    "    \"\"\"\n",
    "\n",
    "    sql_query = state[\"sql_query_generated\"]\n",
    "\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        conn = sqlite3.connect(os.path.join(db_dir_path, db))\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Split multiple SQL statements (separated by semicolons)\n",
    "        # Filter out empty statements and strip whitespace\n",
    "        queries = [q.strip() for q in sql_query.split(\";\") if q.strip()]\n",
    "\n",
    "        all_results = []\n",
    "\n",
    "        # Execute each statement separately\n",
    "        for idx, query in enumerate(queries):\n",
    "            cursor.execute(query)\n",
    "\n",
    "            # Fetch results for this statement\n",
    "            results = cursor.fetchall()\n",
    "\n",
    "            if results:\n",
    "                # Get column names from cursor description\n",
    "                column_names = [description[0] for description in cursor.description]\n",
    "\n",
    "                # Convert to DataFrame for better readability\n",
    "                df = pd.DataFrame(results, columns=column_names)\n",
    "\n",
    "                # Format result with query number if multiple queries exist\n",
    "                if len(queries) > 1:\n",
    "                    result_text = f\"Query {idx + 1}:\\n{query}\\n\\nResult:\\n{df.to_string(index=False)}\"\n",
    "                else:\n",
    "                    result_text = df.to_string(index=False)\n",
    "\n",
    "                all_results.append(result_text)\n",
    "            else:\n",
    "                # Handle queries that return no rows (e.g., CREATE, INSERT, UPDATE)\n",
    "                if len(queries) > 1:\n",
    "                    all_results.append(\n",
    "                        f\"Query {idx + 1}:\\n{query}\\n\\nResult: No rows returned\"\n",
    "                    )\n",
    "                else:\n",
    "                    all_results.append(\"No results found.\")\n",
    "\n",
    "        # Close the database connection\n",
    "        conn.close()\n",
    "\n",
    "        # Store formatted results in state\n",
    "        if all_results:\n",
    "            state[\"result_for_sql_query\"] = \"\\n\\n\" + \"=\" * 80 + \"\\n\\n\".join(all_results)\n",
    "        else:\n",
    "            state[\"result_for_sql_query\"] = (\n",
    "                \"Query executed successfully but returned no results.\"\n",
    "            )\n",
    "\n",
    "        # Clear any previous error\n",
    "        state[\"error_message\"] = \"\"\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        # Handle SQLite-specific errors\n",
    "        state[\"error_message\"] = f\"SQL Execution Error: {str(e)}\"\n",
    "        state[\"result_for_sql_query\"] = \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle unexpected errors\n",
    "        state[\"error_message\"] = f\"Unexpected Error: {str(e)}\"\n",
    "        state[\"result_for_sql_query\"] = \"\"\n",
    "\n",
    "    finally:\n",
    "        # Ensure connection is closed even if an error occurs\n",
    "        if \"conn\" in locals():\n",
    "            conn.close()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b1324",
   "metadata": {},
   "source": [
    "#### Error Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74d449d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorCorrectionResponse(BaseModel):\n",
    "    corrected_sql_query: str = Field(\n",
    "        description=\"The fixed SQL query that should resolve the error.\",\n",
    "    )\n",
    "    error_analysis: str = Field(\n",
    "        description=\"Brief explanation of what was wrong and how it was fixed (max 50 words).\",\n",
    "    )\n",
    "\n",
    "\n",
    "def error_correction_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Attempts to automatically fix SQL errors by analyzing the error message and regenerating the query.\n",
    "\n",
    "    This function:\n",
    "    1. Analyzes the SQL error message and failed query\n",
    "    2. Uses the schema definition to understand what went wrong\n",
    "    3. Generates a corrected SQL query\n",
    "    4. Implements retry logic with a maximum of 3 attempts\n",
    "    5. Returns an apology message if all retries fail\n",
    "    \"\"\"\n",
    "\n",
    "    error_message = state[\"error_message\"]\n",
    "    failed_sql_query = state[\"sql_query_generated\"]\n",
    "    user_query = state[\"user_query\"]\n",
    "    iteration = state.get(\"curr_iteration\", 0)\n",
    "\n",
    "    # Maximum retry limit - prevent infinite loops\n",
    "    MAX_RETRIES = 3\n",
    "\n",
    "    if iteration > MAX_RETRIES:\n",
    "        state[\"final_answer\"] = (\n",
    "            f\"I apologize, but I'm unable to generate a correct SQL query for your question after {MAX_RETRIES} attempts. \"\n",
    "            f\"The error encountered was: {error_message}\\n\\n\"\n",
    "            \"Please try rephrasing your question or contact support for assistance.\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    prompt = f\"\"\"You are an expert SQL debugger. A SQL query has failed and you need to fix it.\n",
    "\n",
    "{SCHEMA_DEFINITION}\n",
    "\n",
    "ORIGINAL USER QUESTION: \"{user_query}\"\n",
    "\n",
    "FAILED SQL QUERY:\n",
    "{failed_sql_query}\n",
    "\n",
    "ERROR MESSAGE:\n",
    "{error_message}\n",
    "\n",
    "COMMON SQL ERRORS AND FIXES:\n",
    "\n",
    "1. COLUMN NOT FOUND:\n",
    "   - Check spelling of column names against schema\n",
    "   - Ensure table aliases match the columns being referenced\n",
    "   - Use table.column notation for ambiguous columns\n",
    "\n",
    "2. TABLE NOT FOUND:\n",
    "   - Verify table name spelling matches schema exactly\n",
    "   - Check for typos (e.g., 'order_item' vs 'order_items')\n",
    "\n",
    "3. SYNTAX ERRORS:\n",
    "   - Missing commas between column names\n",
    "   - Unmatched parentheses in subqueries\n",
    "   - Missing ON clause in JOIN statements\n",
    "   - Incorrect GROUP BY usage (all non-aggregated columns must be in GROUP BY)\n",
    "\n",
    "4. AGGREGATION ERRORS:\n",
    "   - Ensure all non-aggregated columns appear in GROUP BY\n",
    "   - Use HAVING for filtering aggregated results, WHERE for row-level filters\n",
    "   - Don't mix aggregated and non-aggregated columns incorrectly\n",
    "\n",
    "5. JOIN ERRORS:\n",
    "   - Ensure foreign key relationships are correct\n",
    "   - Use proper join types (INNER vs LEFT JOIN)\n",
    "   - Include ON clause with valid join conditions\n",
    "\n",
    "DEBUGGING STEPS:\n",
    "1. Identify the exact error from the error message\n",
    "2. Locate the problematic part of the query\n",
    "3. Reference the schema to find correct column/table names\n",
    "4. Fix the issue while preserving the original query intent\n",
    "5. Ensure the corrected query still answers the user's question\n",
    "\n",
    "Generate a corrected SQL query. No markdown formatting, no explanations in the query itself.\n",
    "\n",
    "Corrected SQL Query:\"\"\"\n",
    "\n",
    "    structured_llm = llm.with_structured_output(ErrorCorrectionResponse)\n",
    "\n",
    "    response = structured_llm.invoke(prompt)\n",
    "\n",
    "    # Clean the corrected SQL query\n",
    "    corrected_query = response.corrected_sql_query.strip()\n",
    "    corrected_query = corrected_query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "    # Update state with corrected query\n",
    "    state[\"sql_query_generated\"] = corrected_query\n",
    "    state[\"error_message\"] = \"\"  # Clear error to trigger retry\n",
    "    state[\"curr_iteration\"] = iteration + 1  # Increment retry counter\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe39e41b",
   "metadata": {},
   "source": [
    "#### Analysis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c08ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Agent\n",
    "class AnalysisResponse(BaseModel):\n",
    "    natural_language_answer: str = Field(\n",
    "        description=\"Clear, concise natural language explanation of the query results.\",\n",
    "    )\n",
    "    key_insights: list[str] = Field(\n",
    "        description=\"List of 2-3 key takeaways or insights from the data.\",\n",
    "    )\n",
    "    needs_visualization: bool = Field(\n",
    "        description=\"Whether the data would benefit from a chart/graph visualization.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def analysis_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Converts SQL query results into natural language answers.\n",
    "    \n",
    "    This function:\n",
    "    1. Takes the raw SQL results and the original user question\n",
    "    2. Generates a human-readable explanation of the findings\n",
    "    3. Identifies key insights from the data\n",
    "    4. Determines if visualization would enhance understanding\n",
    "    5. Formats the response in a clear, user-friendly manner\n",
    "    \"\"\"\n",
    "    \n",
    "    user_query = state[\"user_query\"]\n",
    "    sql_query = state[\"sql_query_generated\"]\n",
    "    query_result = state[\"result_for_sql_query\"]\n",
    "    \n",
    "    prompt = f\"\"\"You are a data analyst expert who explains database query results in clear, natural language.\n",
    "\n",
    "ORIGINAL USER QUESTION: \"{user_query}\"\n",
    "\n",
    "SQL QUERY EXECUTED:\n",
    "{sql_query}\n",
    "\n",
    "QUERY RESULTS:\n",
    "{query_result}\n",
    "\n",
    "ANALYSIS GUIDELINES:\n",
    "\n",
    "1. ANSWER FORMAT:\n",
    "   - Start with a direct answer to the user's question\n",
    "   - Use clear, conversational language (avoid technical jargon)\n",
    "   - Present numbers with proper formatting (e.g., \"$1,234.56\" for money, \"1,234\" for counts)\n",
    "   \n",
    "2. DATA PRESENTATION:\n",
    "   - For single values: state them clearly (e.g., \"The total revenue was $45,678\")\n",
    "   - For lists/rankings: use bullet points or numbered lists\n",
    "   - For comparisons: highlight differences explicitly\n",
    "   - For trends: describe the pattern observed\n",
    "\n",
    "3. CONTEXT & INSIGHTS:\n",
    "   - Explain what the numbers mean in business terms\n",
    "   - Identify notable patterns or outliers\n",
    "   - Provide 2-3 key takeaways from the data\n",
    "   \n",
    "4. MULTI-PART QUESTIONS:\n",
    "   - Address each part of the question separately\n",
    "   - Use clear section headers if needed\n",
    "   - Maintain logical flow in the answer\n",
    "\n",
    "5. VISUALIZATION CONSIDERATION:\n",
    "   - Determine if a chart would help visualize the data\n",
    "   - Consider visualization for: trends over time, comparisons, distributions, rankings\n",
    "\n",
    "Generate a comprehensive, user-friendly answer based on the query results.\"\"\"\n",
    "\n",
    "    structured_llm = llm.with_structured_output(AnalysisResponse)\n",
    "    \n",
    "    response = structured_llm.invoke(prompt)\n",
    "    \n",
    "    # Format the final answer with insights\n",
    "    final_answer_parts = [response.natural_language_answer]\n",
    "    \n",
    "    if response.key_insights:\n",
    "        final_answer_parts.append(\"\\n\\n**Key Insights:**\")\n",
    "        for i, insight in enumerate(response.key_insights, 1):\n",
    "            final_answer_parts.append(f\"{i}. {insight}\")\n",
    "    \n",
    "    state[\"final_answer\"] = \"\\n\".join(final_answer_parts)\n",
    "    state[\"needs_plotly_figure\"] = response.needs_visualization\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b080dbb",
   "metadata": {},
   "source": [
    "#### Decide Vizualization Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8281c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VisualizationDecisionResponse(BaseModel):\n",
    "    needs_visualization: bool = Field(\n",
    "        description=\"Whether the data would benefit from visualization.\",\n",
    "    )\n",
    "    visualization_type: str = Field(\n",
    "        description=\"Type of chart: 'bar', 'line', 'pie', 'scatter', or 'none'.\",\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Brief explanation for the decision (max 30 words).\",\n",
    "    )\n",
    "\n",
    "\n",
    "def decide_visualization_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Determines if visualization would enhance data understanding.\n",
    "    \n",
    "    This function:\n",
    "    1. Analyzes the query results and question type\n",
    "    2. Decides if a chart would add value\n",
    "    3. Selects the most appropriate chart type\n",
    "    4. Provides reasoning for the decision\n",
    "    \"\"\"\n",
    "    \n",
    "    user_query = state[\"user_query\"]\n",
    "    query_result = state[\"result_for_sql_query\"]\n",
    "    \n",
    "    # Skip if no results or already has error\n",
    "    if not query_result or \"No results found\" in query_result or state.get(\"error_message\"):\n",
    "        state[\"needs_plotly_figure\"] = False\n",
    "        state[\"type_of_plotly_figure\"] = \"none\"\n",
    "        return state\n",
    "    \n",
    "    prompt = f\"\"\"You are a data visualization expert. Analyze whether a chart would enhance understanding of this data.\n",
    "\n",
    "USER QUESTION: \"{user_query}\"\n",
    "\n",
    "QUERY RESULTS (first 500 chars):\n",
    "{query_result[:500]}\n",
    "\n",
    "VISUALIZATION DECISION RULES:\n",
    "\n",
    "1. BAR CHART - Use for:\n",
    "   - Comparing categories (top products, sales by region)\n",
    "   - Ranking items (top 10 customers)\n",
    "   - Discrete comparisons\n",
    "\n",
    "2. LINE CHART - Use for:\n",
    "   - Trends over time (monthly revenue, daily orders)\n",
    "   - Time series data\n",
    "   - Sequential patterns\n",
    "\n",
    "3. PIE CHART - Use for:\n",
    "   - Proportions/percentages (market share, category distribution)\n",
    "   - Part-to-whole relationships\n",
    "   - Maximum 5-7 categories\n",
    "\n",
    "4. SCATTER PLOT - Use for:\n",
    "   - Correlations between two variables\n",
    "   - Distribution patterns\n",
    "   - Outlier detection\n",
    "\n",
    "5. NO VISUALIZATION - When:\n",
    "   - Single value answers (\"total: 42\")\n",
    "   - Simple yes/no responses\n",
    "   - Text-heavy results\n",
    "   - Already clear from numbers alone\n",
    "\n",
    "Determine if visualization would add value and select the best chart type.\"\"\"\n",
    "\n",
    "    structured_llm = llm.with_structured_output(VisualizationDecisionResponse)\n",
    "    \n",
    "    response = structured_llm.invoke(prompt)\n",
    "    \n",
    "    state[\"needs_plotly_figure\"] = response.needs_visualization\n",
    "    state[\"type_of_plotly_figure\"] = response.visualization_type\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237309eb",
   "metadata": {},
   "source": [
    "#### Visualization Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "603c8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotlyCodeResponse(BaseModel):\n",
    "    plotly_code: str = Field(\n",
    "        description=\"Python code to generate a Plotly visualization.\",\n",
    "    )\n",
    "    chart_title: str = Field(\n",
    "        description=\"Title for the chart.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def visualization_agent(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Generates Plotly visualization code from query results.\n",
    "    \n",
    "    This function:\n",
    "    1. Takes the query results and chart type\n",
    "    2. Generates Python code using Plotly\n",
    "    3. Executes the code to create a figure\n",
    "    4. Exports the figure as JSON for rendering\n",
    "    \"\"\"\n",
    "    \n",
    "    user_query = state[\"user_query\"]\n",
    "    query_result = state[\"result_for_sql_query\"]\n",
    "    chart_type = state[\"type_of_plotly_figure\"]\n",
    "    \n",
    "    try:\n",
    "        import io\n",
    "        \n",
    "        # Extract data from the formatted string\n",
    "        # This is a simplified parser - may need adjustment based on actual format\n",
    "        lines = query_result.strip().split('\\n')\n",
    "        \n",
    "        # For simplicity, let's assume the data can be parsed\n",
    "        # You may need to enhance this based on your actual result format\n",
    "        \n",
    "        prompt = f\"\"\"Generate Python code using Plotly to create a {chart_type} chart for this data.\n",
    "\n",
    "USER QUESTION: \"{user_query}\"\n",
    "\n",
    "QUERY RESULTS:\n",
    "{query_result}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Use plotly.graph_objects (as 'go') or plotly.express (as 'px')\n",
    "2. Data is available as a pandas DataFrame named 'df'\n",
    "3. Create a {chart_type} chart\n",
    "4. Add proper title, labels, and formatting\n",
    "5. Variable must be named 'fig'\n",
    "6. NO import statements (already imported)\n",
    "7. NO fig.show() or display commands\n",
    "8. Limit to top 20 data points if there are many rows\n",
    "9. Use appropriate colors and styling\n",
    "10. Add hover information\n",
    "\n",
    "EXAMPLE STRUCTURE:\n",
    "```python\n",
    "# Parse data from results\n",
    "df = pd.DataFrame({{\n",
    "    'column1': [values],\n",
    "    'column2': [values]\n",
    "}})\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(...)\n",
    "# or\n",
    "fig = px.{chart_type}(df, ...)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Chart Title',\n",
    "    xaxis_title='X Label',\n",
    "    yaxis_title='Y Label'\n",
    ")\n",
    "\n",
    "Generate the complete Plotly code:\"\"\"\n",
    "\n",
    "        structured_llm = llm.with_structured_output(PlotlyCodeResponse)\n",
    "        \n",
    "        response = structured_llm.invoke(prompt)\n",
    "        \n",
    "        plotly_code = response.plotly_code.strip()\n",
    "        plotly_code = plotly_code.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        # Prepare execution environment\n",
    "        exec_globals = {\n",
    "            'pd': pd,\n",
    "            'json': json\n",
    "        }\n",
    "        \n",
    "        # Import Plotly\n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.express as px\n",
    "        exec_globals['go'] = go\n",
    "        exec_globals['px'] = px\n",
    "        \n",
    "        # Execute the generated code\n",
    "        exec(plotly_code, exec_globals)\n",
    "        \n",
    "        # Get the figure\n",
    "        fig = exec_globals.get('fig')\n",
    "        \n",
    "        if fig is None:\n",
    "            raise ValueError(\"Generated code did not create a 'fig' variable\")\n",
    "        \n",
    "        # Convert to JSON\n",
    "        state[\"plotly_figure_json_string\"] = fig.to_json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Visualization generation error: {e}\")\n",
    "        state[\"plotly_figure_json_string\"] = \"\"\n",
    "        state[\"needs_plotly_figure\"] = False\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6da8ea",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca2f4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_retry(state: GraphState) -> str:\n",
    "    \"\"\"Decide whether to retry after an error\"\"\"\n",
    "    if state.get(\"error_message\"):\n",
    "        iteration = state.get(\"curr_iteration\", 0)\n",
    "        if iteration <= 3:\n",
    "            return \"retry\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "def should_visualize(state: GraphState) -> str:\n",
    "    \"\"\"Decide whether to generate visualization\"\"\"\n",
    "    if state.get(\"needs_plotly_figure\", False) and state.get(\"type_of_plotly_figure\") != \"none\":\n",
    "        return \"visualize\"\n",
    "    return \"skip\"\n",
    "\n",
    "\n",
    "def check_relevance(state: GraphState) -> str:\n",
    "    \"\"\"Check if question is relevant to proceed\"\"\"\n",
    "    # If final_answer is already set by guardrails, it's either greeting or out-of-scope\n",
    "    if state.get(\"final_answer\"):\n",
    "        return \"end\"\n",
    "    if state.get(\"is_question_relavant\", False):\n",
    "        return \"relevant\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decf299",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def create_text2sql_graph():\n",
    "    \"\"\"Create the LangGraph workflow for Text-to-SQL with visualization\"\"\"\n",
    "\n",
    "    workflow = StateGraph(GraphState)\n",
    "\n",
    "    # Add nodes\n",
    "    workflow.add_node(\"guardrails_agent\", guardrails_agent)\n",
    "    workflow.add_node(\"sql_generation_agent\", sql_generation_agent)\n",
    "    workflow.add_node(\"execute_sql\", execute_sql)\n",
    "    workflow.add_node(\"error_correction_agent\", error_correction_agent)\n",
    "    workflow.add_node(\"analysis_agent\", analysis_agent)\n",
    "    workflow.add_node(\"decide_visualization_agent\", decide_visualization_agent)\n",
    "    workflow.add_node(\"visualization_agent\", visualization_agent)\n",
    "\n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"guardrails_agent\")\n",
    "\n",
    "    # Guardrails → SQL Generation (if relevant)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"guardrails_agent\",\n",
    "        check_relevance,\n",
    "        {\"relevant\": \"sql_generation_agent\", \"end\": END},\n",
    "    )\n",
    "\n",
    "    # SQL Generation → Execute SQL\n",
    "    workflow.add_edge(\"sql_generation_agent\", \"execute_sql\")\n",
    "\n",
    "    # Execute SQL → Analysis or Error Correction\n",
    "    workflow.add_conditional_edges(\n",
    "        \"execute_sql\",\n",
    "        should_retry,\n",
    "        {\n",
    "            \"success\": \"analysis_agent\",\n",
    "            \"retry\": \"error_correction_agent\",\n",
    "            \"end\": \"analysis_agent\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Error Correction → Execute SQL (retry)\n",
    "    workflow.add_edge(\"error_correction_agent\", \"execute_sql\")\n",
    "\n",
    "    # Analysis → Decide Visualization\n",
    "    workflow.add_edge(\"analysis_agent\", \"decide_visualization_agent\")\n",
    "\n",
    "    # Decide Visualization → Generate or Skip\n",
    "    workflow.add_conditional_edges(\n",
    "        \"decide_visualization_agent\",\n",
    "        should_visualize,\n",
    "        {\"visualize\": \"visualization_agent\", \"skip\": END},\n",
    "    )\n",
    "\n",
    "    # Visualization → End\n",
    "    workflow.add_edge(\"visualization_agent\", END)\n",
    "\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45922352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb1f8c95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96158c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b9887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ee0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
